# GPT-2 Text Generator with Gradio

This project is a simple text generation tool that uses the GPT-2 model from Hugging Face's Transformers library, integrated with a Gradio interface. Users can input text and receive generated responses, with basic filtering for inappropriate content and improvements for factual accuracy. The project is designed for easy experimentation with GPT-2 text generation through a user-friendly web interface.

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/percivalyan/VariaGPT-2/blob/main/VariaGPT_2.ipynb)
